{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a971b497",
   "metadata": {},
   "source": [
    "# PaST — CNN+DeepSets PPO (Colab/T4)\n",
    "\n",
    "This notebook trains one of the new *CNN+DeepSets* PPO variants (same job×family action space + best-start decoding), then evaluates it with Greedy / SGBS / EAS or SGBS+EAS.\n",
    "\n",
    "**Typical flow**\n",
    "1) Install deps (Colab)\n",
    "2) Train: `python -m PaST.train_ppo ...`\n",
    "3) Auto-pick latest checkpoint\n",
    "4) Evaluate: `python -m PaST.run_eval_eas_* ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2760cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /content\n",
      "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "torch: 2.9.0+cu126\n",
      "cuda available: True\n",
      "gpu: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import os, sys, subprocess, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "print(\"CWD:\", ROOT)\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "# Make sure imports like `import PaST` work\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "# Basic sanity: torch + GPU\n",
    "import torch\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67929c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PaST'...\n",
      "remote: Enumerating objects: 356, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
      "remote: Total 356 (delta 10), reused 16 (delta 5), pack-reused 329 (from 1)\u001b[K\n",
      "Receiving objects: 100% (356/356), 125.83 MiB | 41.38 MiB/s, done.\n",
      "Resolving deltas: 100% (178/178), done.\n"
     ]
    }
   ],
   "source": [
    "# Colab installs (safe to re-run).\n",
    "# If you're not on Colab and already have deps, you can skip this cell.\n",
    "!rm -rf PaST\n",
    "!git clone https://github.com/Abdellahbado/PaST\n",
    "\n",
    "!pip -q install -r PaST/requirements.txt\n",
    "!pip -q install pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a9156",
   "metadata": {},
   "source": [
    "## Train (long-run-friendly hyperparams)\n",
    "\n",
    "Defaults here are chosen to **keep learning for a long time**:\n",
    "- Cosine LR decay with a non-trivial end LR (`lr_end_factor=0.1`)\n",
    "- Cosine entropy decay (explore early, still some exploration late)\n",
    "- Target KL to prevent updates collapsing\n",
    "- Curriculum enabled (helps early stability): starts on *small* horizons then gradually introduces larger ones, while also annealing the epsilon-constraint slack range\n",
    "\n",
    "Adjust `TOTAL_ENV_STEPS` depending on runtime budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a0e9bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4280133346.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create checkpoint directory in Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory in Drive\n",
    "import os\n",
    "drive_checkpoint_dir = '/content/drive/MyDrive/PaST_checkpoints'\n",
    "os.makedirs(drive_checkpoint_dir, exist_ok=True)\n",
    "print(f\"Checkpoint directory: {drive_checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75870e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick ONE variant_id:\n",
    "# - ppo_family_q4_ctx13_beststart_cwe (recommended default)\n",
    "# - ppo_duration_aware_family_ctx13_cnn\n",
    "\n",
    "VARIANT_ID = \"ppo_family_q4_ctx13_beststart_cwe\"\n",
    "SEED = 0\n",
    "OUT_DIR = \"/content/drive/MyDrive/PaST_checkpoints/runs_family_beststart_cwe\"\n",
    "\n",
    "# Main training knobs (T4-friendly defaults)\n",
    "NUM_ENVS = 128\n",
    "ROLLOUT_LEN = 512\n",
    "TOTAL_ENV_STEPS = 20_000_000\n",
    "\n",
    "LR = 3e-4\n",
    "LR_SCHEDULE = \"cosine\"\n",
    "LR_END_FACTOR = 0.1\n",
    "\n",
    "ENT_SCHEDULE = \"cosine\"\n",
    "ENT_START = 0.02\n",
    "ENT_END = 0.002\n",
    "ENT_DECAY_FRAC = 0.8\n",
    "\n",
    "PPO_EPOCHS = 4\n",
    "NUM_MINIBATCHES = 64\n",
    "CLIP_EPS = 0.2\n",
    "VALUE_COEF = 0.5\n",
    "MAX_GRAD_NORM = 0.5\n",
    "TARGET_KL = 0.03\n",
    "\n",
    "CURRICULUM = True\n",
    "CURRICULUM_FRAC = 0.3\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    \"-m\",\n",
    "    \"PaST.train_ppo\",\n",
    "    \"--variant_id\",\n",
    "    VARIANT_ID,\n",
    "    \"--seed\",\n",
    "    str(SEED),\n",
    "    \"--device\",\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"--output_dir\",\n",
    "    OUT_DIR,\n",
    "    \"--num_envs\",\n",
    "    str(NUM_ENVS),\n",
    "    \"--rollout_length\",\n",
    "    str(ROLLOUT_LEN),\n",
    "    \"--total_env_steps\",\n",
    "    str(TOTAL_ENV_STEPS),\n",
    "    \"--learning_rate\",\n",
    "    str(LR),\n",
    "    \"--lr_schedule\",\n",
    "    LR_SCHEDULE,\n",
    "    \"--lr_end_factor\",\n",
    "    str(LR_END_FACTOR),\n",
    "    \"--ppo_epochs\",\n",
    "    str(PPO_EPOCHS),\n",
    "    \"--num_minibatches\",\n",
    "    str(NUM_MINIBATCHES),\n",
    "    \"--clip_eps\",\n",
    "    str(CLIP_EPS),\n",
    "    \"--value_coef\",\n",
    "    str(VALUE_COEF),\n",
    "    \"--max_grad_norm\",\n",
    "    str(MAX_GRAD_NORM),\n",
    "    \"--target_kl\",\n",
    "    str(TARGET_KL),\n",
    "    \"--entropy_schedule\",\n",
    "    ENT_SCHEDULE,\n",
    "    \"--entropy_coef_start\",\n",
    "    str(ENT_START),\n",
    "    \"--entropy_coef_end\",\n",
    "    str(ENT_END),\n",
    "    \"--entropy_decay_fraction\",\n",
    "    str(ENT_DECAY_FRAC),\n",
    "]\n",
    "if CURRICULUM:\n",
    "    cmd += [\"--curriculum\", \"--curriculum_fraction\", str(CURRICULUM_FRAC)]\n",
    "\n",
    "print(\" \".join(cmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "!{' '.join(cmd)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4041bc",
   "metadata": {},
   "source": [
    "## Find the latest checkpoint\n",
    "This grabs the most recent `latest.pt` under the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "ckpts = glob.glob(f\"{OUT_DIR}/**/checkpoints/latest.pt\", recursive=True)\n",
    "if not ckpts:\n",
    "    raise FileNotFoundError(f\"No latest.pt found under {OUT_DIR}/\")\n",
    "\n",
    "ckpts_sorted = sorted(ckpts, key=lambda p: Path(p).stat().st_mtime)\n",
    "CKPT = ckpts_sorted[-1]\n",
    "print(\"Using checkpoint:\", CKPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed3550",
   "metadata": {},
   "source": [
    "## Evaluate (Greedy / SGBS / EAS / SGBS+EAS)\n",
    "Choose the script based on the variant family:\n",
    "- `run_eval_eas_family_q4_beststart` for `ppo_family_*_beststart_*`\n",
    "- `run_eval_eas_duration_aware` for `ppo_duration_aware_*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f594c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_SEED = 42\n",
    "NUM_INSTANCES = 16\n",
    "SCALE = \"small\"  # small|medium|large\n",
    "EPS_STEPS = 5\n",
    "\n",
    "METHOD = \"sgbs_eas\"  # eas|sgbs_eas\n",
    "BETA = \"4\"\n",
    "GAMMA = \"4\"\n",
    "MAX_ITERS = 50\n",
    "EAS_LR = 0.003\n",
    "EAS_IL = 0.01\n",
    "SAMPLES_PER_ITER = 32\n",
    "\n",
    "if \"duration_aware\" in VARIANT_ID:\n",
    "    eval_mod = \"PaST.run_eval_eas_duration_aware\"\n",
    "else:\n",
    "    eval_mod = \"PaST.run_eval_eas_family_q4_beststart\"\n",
    "\n",
    "eval_cmd = [\n",
    "    sys.executable,\n",
    "    \"-m\",\n",
    "    eval_mod,\n",
    "    \"--checkpoint\",\n",
    "    CKPT,\n",
    "    \"--variant_id\",\n",
    "    VARIANT_ID,\n",
    "    \"--eval_seed\",\n",
    "    str(EVAL_SEED),\n",
    "    \"--num_instances\",\n",
    "    str(NUM_INSTANCES),\n",
    "    \"--scale\",\n",
    "    SCALE,\n",
    "    \"--epsilon_steps\",\n",
    "    str(EPS_STEPS),\n",
    "    \"--method\",\n",
    "    METHOD,\n",
    "    \"--beta\",\n",
    "    BETA,\n",
    "    \"--gamma\",\n",
    "    GAMMA,\n",
    "    \"--max_iterations\",\n",
    "    str(MAX_ITERS),\n",
    "    \"--eas_lr\",\n",
    "    str(EAS_LR),\n",
    "    \"--eas_il_weight\",\n",
    "    str(EAS_IL),\n",
    "    \"--samples_per_iter\",\n",
    "    str(SAMPLES_PER_ITER),\n",
    "]\n",
    "print(\" \".join(eval_cmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{' '.join(eval_cmd)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b3a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
