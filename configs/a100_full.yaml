# PaST-SM PPO Training: A100 Full Training Config
# Full production training run - designed for long training without early convergence

# Variant and identity
variant_id: ppo_short_base
seed: 0

# Environment (larger batch for A100)
num_envs: 1024
rollout_length: 128

# PPO hyperparameters
gamma: 0.99
gae_lambda: 0.95
clip_eps: 0.2
value_coef: 0.5
entropy_coef: 0.01
learning_rate: 0.0003
max_grad_norm: 1.0
ppo_epochs: 4
num_minibatches: 16
target_kl: 0.02
normalize_advantages: true

# Learning rate schedule (decay to 10% by end of training)
lr_schedule: "cosine"
lr_end_factor: 0.1

# Entropy schedule (start high, decay gradually to maintain exploration)
entropy_schedule: "cosine"
entropy_coef_start: 0.05       # Start 5x higher for exploration
entropy_coef_end: 0.001        # End low for exploitation
entropy_decay_fraction: 0.7    # Decay over 70% of training

# Curriculum learning (start with easier instances)
curriculum: true
curriculum_fraction: 0.25      # Anneal difficulty over first 25% of training

# Training budget (100M steps)
total_env_steps: 100000000

# Evaluation
eval_every_updates: 50
num_eval_instances: 512

# Checkpointing
save_latest_every_updates: 10
save_latest_every_minutes: 15.0
num_milestone_checkpoints: 4

# Logging
log_every_updates: 1

# Device
device: cuda

# Debug
anomaly_check_every: 100
